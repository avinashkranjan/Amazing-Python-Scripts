# Youtube Trending Feed Scrapper
# Written by XZANATOL
from optparse import OptionParser
from selenium import webdriver
import pandas as pd
import mongoengine
import pymongo
import time
import sys

# Help menu
usage = """
<Script> [Options]

[Options]
    -h, --help    Shows this help message and exit.
    -c, --csv     Saves extracted contents to a CSV file.
    -m, --mongo   Saves extracted contents to a MongoDB.
"""

# Load args
parser = OptionParser()
parser.add_option("-c", "--csv", action="store_true", dest="csv",
                  help="Saves extracted contents to a CSV file.")
parser.add_option("-m", "--mongo", action="store_true",
                  dest="mongo", help="Saves extracted contents to a MongoDB.")

# Defined DataFrame to avoid check errors
df = pd.DataFrame()

# MongoDB Collection (Table) Template


class Trending(mongoengine.Document):
    section = mongoengine.StringField(required=True)
    title = mongoengine.StringField(required=True)
    channel = mongoengine.StringField(required=True)
    link = mongoengine.StringField(required=True)
    views = mongoengine.StringField(required=True)
    date = mongoengine.StringField(required=True)

    meta = {"indexes": ["section"]}


def load_driver():
    """Load Chrome webdriver."""
    driver = webdriver.Chrome("chromedriver.exe")
    return driver


def page_scrap(driver):
    """Scrap YouTube trending feed."""
    # pages to be scrapped: Now, Music, Gaming, Movies
    pages = ["https://www.youtube.com/feed/trending",
             "https://www.youtube.com/feed/trending?bp=4gINGgt5dG1hX2NoYXJ0cw%3D%3D",
             "https://www.youtube.com/feed/trending?bp=4gIcGhpnYW1pbmdfY29ycHVzX21vc3RfcG9wdWxhcg%3D%3D",
             "https://www.youtube.com/feed/trending?bp=4gIKGgh0cmFpbGVycw%3D%3D"]
    sections = ["Now", "Music", "Gaming", "Movies"]

    for num in range(4):
        driver.get(pages[num])
        time.sleep(3)  # Make sure that all the page is loaded
        # Extract first 10 contents
        cards = driver.find_elements_by_tag_name("ytd-video-renderer")[:10]
        links = driver.find_elements_by_id("video-title")[:10]
        meta_data = driver.find_elements_by_tag_name(
            "ytd-video-meta-block")[:10]
        for i in range(10):
            # Splitted meta data that will be saved
            meta_splitted = meta_data[i].text.split("\n")
            # Sometimes this character is extracted for unknown reasons
            try:
                meta_splitted.remove("â€¢")
            except:
                pass
            section = sections[num]     # Scrapped from which section?
            link = links[i].get_attribute("href")  # Video Link
            title = links[i].text     # Video title
            channel = meta_splitted[0]  # Channel name
            views = meta_splitted[1]  # Video Views
            date = meta_splitted[2]  # Release date

            """Arguments validation is better than making a scrapping algorithm for each"""
            if mongo:
                save_to_db(section, title, channel, link, views, date)
            if csv:
                append_to_df(section, title, channel, link, views, date)

        print(f"[+]Finished scraping '{sections[num]}' section!")

    # last validation for csv
    if csv:
        save_to_csv()


def save_to_db(section, title, channel, link, views, date):
    """Saves a record to database."""
    # Create object
    record = Trending(
        section=section,
        title=title,
        channel=channel,
        link=link,
        views=views,
        date=date)
    # Save record
    record.save()


def append_to_df(section, title, channel, link, views, date):
    """Appends a record to dataframe."""
    global df
    df = df.append({"section": section,
                    "title": title,
                    "channel": channel,
                    "link": link,
                    "views": views,
                    "date": date, }, ignore_index=True)


def save_to_csv():
    """exports dataframe to a CSV file."""
    global df
    df.to_csv("Youtube.csv", index=False, columns=["section", "title",
                                                   "channel", "link",
                                                   "views", "date"])
    # Function end (eye friendly comment to seperate the function end line)


if __name__ == "__main__":
    (options, args) = parser.parse_args()

    # Flags
    csv = options.csv
    mongo = options.mongo
    # Validate flags
    if not (bool(csv) or bool(mongo)):
        print(usage)
        sys.exit()

    if mongo:
        mongoengine.connect("Youtube")

    driver = load_driver()  # load driver
    page_scrap(driver)  # start scrapping
    print("[+]Done !")
    # End session
    driver.quit()
    sys.exit()
